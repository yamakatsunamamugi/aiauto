"""
çµ±åˆã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«å–å¾—æ©Ÿèƒ½
ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ã€APIã€æ‰‹å‹•å…¥åŠ›ã®3ã¤ã®æ–¹æ³•ã§ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—å¯èƒ½
"""

import json
import os
import asyncio
from typing import Dict, List, Optional, Literal
from datetime import datetime
import logging
import platform
from playwright.async_api import async_playwright, Page
import aiohttp

logger = logging.getLogger(__name__)

class UnifiedModelFetcher:
    """çµ±åˆã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.chrome_user_data_dir = self._get_chrome_user_data_dir()
        self.config_dir = "config"
        os.makedirs(self.config_dir, exist_ok=True)
        
        # AIã‚µãƒ¼ãƒ“ã‚¹ã®è¨­å®š
        self.ai_services = {
            "chatgpt": {
                "url": "https://chat.openai.com",
                "model_selector": 'button[aria-haspopup="menu"]:has-text("GPT")',
                "model_list_selector": '[role="menuitem"]',
                "wait_selector": 'main',
                "api_endpoint": "https://api.openai.com/v1/models",
                "default_models": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo", "gpt-4", "gpt-3.5-turbo"]
            },
            "claude": {
                "url": "https://claude.ai/new",
                "model_selector": 'button[aria-label*="model"]',
                "model_list_selector": '[role="option"]',
                "wait_selector": 'main',
                "api_endpoint": None,  # Claude APIã¯ç›´æ¥ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆå–å¾—ä¸å¯
                "default_models": ["claude-3.5-sonnet", "claude-3-opus", "claude-3-sonnet", "claude-3-haiku"]
            },
            "gemini": {
                "url": "https://gemini.google.com/app",
                "model_selector": 'button[aria-label*="Model"]',
                "model_list_selector": '[role="menuitem"]',
                "wait_selector": 'main',
                "api_endpoint": None,  # Gemini APIã¯åˆ¥é€”è¨­å®šå¿…è¦
                "default_models": ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-pro"]
            },
            "genspark": {
                "url": "https://www.genspark.ai",
                "model_selector": None,
                "model_list_selector": None,
                "wait_selector": 'body',
                "api_endpoint": None,
                "default_models": ["default", "research", "advanced"]
            },
            "google_ai_studio": {
                "url": "https://aistudio.google.com/app/prompts/new_chat",
                "model_selector": 'button[aria-label*="Model"]',
                "model_list_selector": '[role="option"]',
                "wait_selector": 'main',
                "api_endpoint": None,
                "default_models": ["gemini-1.5-pro", "gemini-1.5-flash", "gemini-pro", "palm-2"]
            }
        }
    
    def _get_chrome_user_data_dir(self) -> str:
        """Chromeã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—"""
        system = platform.system()
        home = os.path.expanduser("~")
        
        if system == "Darwin":  # macOS
            return os.path.join(home, "Library/Application Support/Google/Chrome")
        elif system == "Windows":
            return os.path.join(home, "AppData\\Local\\Google\\Chrome\\User Data")
        else:  # Linux
            return os.path.join(home, ".config/google-chrome")
    
    async def fetch_models(
        self, 
        method: Literal["browser", "api", "manual", "cached"] = "browser",
        service: Optional[str] = None,
        api_keys: Optional[Dict[str, str]] = None,
        manual_models: Optional[Dict[str, List[str]]] = None
    ) -> Dict[str, Dict]:
        """
        æŒ‡å®šã•ã‚ŒãŸæ–¹æ³•ã§ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—
        
        Args:
            method: å–å¾—æ–¹æ³• ("browser", "api", "manual", "cached")
            service: ç‰¹å®šã®ã‚µãƒ¼ãƒ“ã‚¹ã®ã¿å–å¾—ã™ã‚‹å ´åˆã«æŒ‡å®š
            api_keys: APIå–å¾—æ™‚ã®APIã‚­ãƒ¼è¾æ›¸
            manual_models: æ‰‹å‹•å…¥åŠ›æ™‚ã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆè¾æ›¸
            
        Returns:
            ã‚µãƒ¼ãƒ“ã‚¹åã‚’ã‚­ãƒ¼ã¨ã—ãŸçµæœè¾æ›¸
        """
        logger.info(f"ğŸ” ãƒ¢ãƒ‡ãƒ«å–å¾—é–‹å§‹ (method={method}, service={service})")
        
        if method == "browser":
            return await self._fetch_models_browser_session(service)
        elif method == "api":
            return await self._fetch_models_api(service, api_keys or {})
        elif method == "manual":
            return self._save_manual_models(manual_models or {})
        elif method == "cached":
            return self._get_cached_models(service)
        else:
            raise ValueError(f"ä¸æ˜ãªå–å¾—æ–¹æ³•: {method}")
    
    async def _fetch_models_browser_session(self, service: Optional[str] = None) -> Dict[str, Dict]:
        """ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã§ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        results = {}
        
        async with async_playwright() as p:
            browser = await p.chromium.launch_persistent_context(
                user_data_dir=self.chrome_user_data_dir,
                headless=False,
                channel="chrome",
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage'
                ]
            )
            
            try:
                services_to_fetch = [service] if service else self.ai_services.keys()
                
                for service_name in services_to_fetch:
                    if service_name not in self.ai_services:
                        logger.warning(f"âŒ ä¸æ˜ãªã‚µãƒ¼ãƒ“ã‚¹: {service_name}")
                        continue
                        
                    try:
                        logger.info(f"ğŸ” {service_name}ã®ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—ä¸­...")
                        service_config = self.ai_services[service_name]
                        models = await self._fetch_single_service(browser, service_name, service_config)
                        
                        results[service_name] = {
                            "models": models,
                            "last_updated": datetime.now().isoformat(),
                            "method": "browser_session"
                        }
                        logger.info(f"âœ… {service_name}: {len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—")
                        
                    except Exception as e:
                        logger.error(f"âŒ {service_name}ã®ãƒ¢ãƒ‡ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
                        results[service_name] = {
                            "error": str(e),
                            "models": self.ai_services[service_name]["default_models"],
                            "method": "fallback"
                        }
                        
            finally:
                await browser.close()
        
        # çµæœã‚’ä¿å­˜
        self._save_results(results, "browser_session")
        return results
    
    async def _fetch_single_service(self, browser, service_name: str, config: Dict) -> List[str]:
        """å€‹åˆ¥ã®AIã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        page = await browser.new_page()
        models = []
        
        try:
            await page.goto(config["url"], wait_until="networkidle", timeout=30000)
            await page.wait_for_selector(config["wait_selector"], timeout=10000)
            await page.wait_for_timeout(2000)
            
            # ã‚µãƒ¼ãƒ“ã‚¹åˆ¥ã®å–å¾—å‡¦ç†
            if service_name == "chatgpt":
                models = await self._fetch_chatgpt_models(page, config)
            elif service_name == "claude":
                models = await self._fetch_claude_models(page, config)
            elif service_name == "gemini":
                models = await self._fetch_gemini_models(page, config)
            elif service_name == "genspark":
                models = config["default_models"]  # å›ºå®šå€¤
            elif service_name == "google_ai_studio":
                models = await self._fetch_google_ai_studio_models(page, config)
                
        except Exception as e:
            logger.error(f"{service_name}ã§ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise
        finally:
            await page.close()
            
        return models
    
    async def _fetch_chatgpt_models(self, page: Page, config: Dict) -> List[str]:
        """ChatGPTã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        models = []
        
        try:
            model_button = await page.wait_for_selector(config["model_selector"], timeout=5000)
            await model_button.click()
            await page.wait_for_timeout(1000)
            
            model_elements = await page.query_selector_all(config["model_list_selector"])
            for element in model_elements:
                text = await element.text_content()
                if text and "GPT" in text:
                    model_name = text.strip().split('\n')[0]
                    if model_name and not any(x in model_name.lower() for x in ["upgrade", "plus", "team"]):
                        models.append(model_name)
            
            await page.keyboard.press("Escape")
            
        except Exception as e:
            logger.warning(f"ChatGPTãƒ¢ãƒ‡ãƒ«å–å¾—ä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}")
            models = config["default_models"]
            
        return models
    
    async def _fetch_claude_models(self, page: Page, config: Dict) -> List[str]:
        """Claudeã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        models = []
        
        try:
            model_elements = await page.query_selector_all('button[class*="model"]')
            if model_elements:
                for element in model_elements:
                    text = await element.text_content()
                    if text and "Claude" in text:
                        model_name = text.strip()
                        if model_name not in models:
                            models.append(model_name)
            
            if not models:
                await page.wait_for_timeout(2000)
                dropdown = await page.query_selector('[aria-label*="model"]')
                if dropdown:
                    await dropdown.click()
                    await page.wait_for_timeout(1000)
                    options = await page.query_selector_all('[role="option"]')
                    for option in options:
                        text = await option.text_content()
                        if text and "Claude" in text:
                            models.append(text.strip())
                    await page.keyboard.press("Escape")
                    
        except Exception as e:
            logger.warning(f"Claudeãƒ¢ãƒ‡ãƒ«å–å¾—ä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}")
            models = config["default_models"]
            
        return models
    
    async def _fetch_gemini_models(self, page: Page, config: Dict) -> List[str]:
        """Geminiã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        models = []
        
        try:
            model_button = await page.query_selector('button[aria-label*="Gemini"]')
            if model_button:
                await model_button.click()
                await page.wait_for_timeout(1000)
                
                options = await page.query_selector_all('[role="menuitem"]')
                for option in options:
                    text = await option.text_content()
                    if text and "Gemini" in text:
                        model_name = text.strip().split('\n')[0]
                        if model_name not in models:
                            models.append(model_name)
                
                await page.keyboard.press("Escape")
            
            if not models:
                settings_button = await page.query_selector('[aria-label*="Settings"]')
                if settings_button:
                    await settings_button.click()
                    await page.wait_for_timeout(1000)
                    model_info = await page.query_selector_all('text=/Gemini.*/i')
                    for info in model_info:
                        text = await info.text_content()
                        if text and "Gemini" in text:
                            models.append(text.strip())
                    
        except Exception as e:
            logger.warning(f"Geminiãƒ¢ãƒ‡ãƒ«å–å¾—ä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}")
            models = config["default_models"]
            
        return models
    
    async def _fetch_google_ai_studio_models(self, page: Page, config: Dict) -> List[str]:
        """Google AI Studioã®ãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        models = []
        
        try:
            model_selector = await page.query_selector('[aria-label*="Select model"]')
            if model_selector:
                await model_selector.click()
                await page.wait_for_timeout(1000)
                
                options = await page.query_selector_all('[role="option"]')
                for option in options:
                    text = await option.text_content()
                    if text and ("Gemini" in text or "PaLM" in text):
                        models.append(text.strip())
                
                await page.keyboard.press("Escape")
                
        except Exception as e:
            logger.warning(f"Google AI Studioãƒ¢ãƒ‡ãƒ«å–å¾—ä¸­ã®ã‚¨ãƒ©ãƒ¼: {e}")
            models = config["default_models"]
            
        return models
    
    async def _fetch_models_api(self, service: Optional[str], api_keys: Dict[str, str]) -> Dict[str, Dict]:
        """APIçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
        results = {}
        services_to_fetch = [service] if service else self.ai_services.keys()
        
        for service_name in services_to_fetch:
            if service_name not in self.ai_services:
                continue
                
            config = self.ai_services[service_name]
            api_key = api_keys.get(service_name)
            
            if service_name == "chatgpt" and api_key and config["api_endpoint"]:
                try:
                    async with aiohttp.ClientSession() as session:
                        headers = {"Authorization": f"Bearer {api_key}"}
                        async with session.get(config["api_endpoint"], headers=headers) as resp:
                            if resp.status == 200:
                                data = await resp.json()
                                models = [
                                    m["id"] for m in data.get("data", []) 
                                    if "gpt" in m["id"].lower()
                                ]
                                results[service_name] = {
                                    "models": sorted(models, reverse=True),
                                    "last_updated": datetime.now().isoformat(),
                                    "method": "api"
                                }
                                logger.info(f"âœ… {service_name}: APIçµŒç”±ã§{len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—")
                            else:
                                logger.error(f"âŒ {service_name}: APIå¿œç­”ã‚¨ãƒ©ãƒ¼ ({resp.status})")
                                results[service_name] = {
                                    "error": f"APIå¿œç­”ã‚¨ãƒ©ãƒ¼: {resp.status}",
                                    "models": config["default_models"],
                                    "method": "fallback"
                                }
                except Exception as e:
                    logger.error(f"âŒ {service_name}: APIã‚¨ãƒ©ãƒ¼ - {e}")
                    results[service_name] = {
                        "error": str(e),
                        "models": config["default_models"],
                        "method": "fallback"
                    }
            else:
                # APIã‚­ãƒ¼ãŒãªã„ã‹APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒãªã„å ´åˆ
                logger.warning(f"âš ï¸ {service_name}: APIã‚­ãƒ¼ã¾ãŸã¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                results[service_name] = {
                    "error": "APIã‚­ãƒ¼ã¾ãŸã¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæœªè¨­å®š",
                    "models": config["default_models"],
                    "method": "fallback"
                }
        
        self._save_results(results, "api")
        return results
    
    def _save_manual_models(self, manual_models: Dict[str, List[str]]) -> Dict[str, Dict]:
        """æ‰‹å‹•å…¥åŠ›ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        results = {}
        
        for service_name, models in manual_models.items():
            if service_name in self.ai_services:
                results[service_name] = {
                    "models": models,
                    "last_updated": datetime.now().isoformat(),
                    "method": "manual"
                }
                logger.info(f"âœ… {service_name}: æ‰‹å‹•ã§{len(models)}å€‹ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š")
            else:
                logger.warning(f"âš ï¸ {service_name}: ä¸æ˜ãªã‚µãƒ¼ãƒ“ã‚¹")
        
        self._save_results(results, "manual")
        return results
    
    def _get_cached_models(self, service: Optional[str] = None) -> Dict[str, Dict]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
        results = {}
        
        # å…¨ã¦ã®ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
        cache_files = [
            ("browser_session", "ai_models_browser_session.json"),
            ("api", "ai_models_api.json"),
            ("manual", "ai_models_manual.json"),
            ("latest", "ai_models_latest.json")  # æ—¢å­˜ã®AIModelUpdaterã®ãƒ•ã‚¡ã‚¤ãƒ«
        ]
        
        for method, filename in cache_files:
            filepath = os.path.join(self.config_dir, filename)
            if os.path.exists(filepath):
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        
                    # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å¿œã˜ã¦å‡¦ç†
                    if "results" in data:
                        cache_results = data["results"]
                    elif "ai_services" in data:
                        # æ—¢å­˜ã®ai_models_latest.jsonã®å½¢å¼
                        cache_results = {}
                        for svc, info in data["ai_services"].items():
                            cache_results[svc] = {
                                "models": info.get("models", []),
                                "last_updated": data.get("last_updated"),
                                "method": method
                            }
                    else:
                        cache_results = data
                    
                    # çµæœã‚’ãƒãƒ¼ã‚¸
                    if service:
                        if service in cache_results:
                            results[service] = cache_results[service]
                            break
                    else:
                        for svc, info in cache_results.items():
                            if svc not in results or self._is_newer(info, results[svc]):
                                results[svc] = info
                                
                except Exception as e:
                    logger.warning(f"âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ ({filename}): {e}")
        
        if not results:
            logger.warning("âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            services_to_return = [service] if service else self.ai_services.keys()
            for svc in services_to_return:
                if svc in self.ai_services:
                    results[svc] = {
                        "models": self.ai_services[svc]["default_models"],
                        "method": "default",
                        "last_updated": datetime.now().isoformat()
                    }
        
        return results
    
    def _is_newer(self, info1: Dict, info2: Dict) -> bool:
        """info1ãŒinfo2ã‚ˆã‚Šæ–°ã—ã„ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            time1 = datetime.fromisoformat(info1.get("last_updated", ""))
            time2 = datetime.fromisoformat(info2.get("last_updated", ""))
            return time1 > time2
        except:
            return False
    
    def _save_results(self, results: Dict, method: str):
        """çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        filename = f"ai_models_{method}.json"
        filepath = os.path.join(self.config_dir, filename)
        
        try:
            output_data = {
                "method": method,
                "last_updated": datetime.now().isoformat(),
                "results": results
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, ensure_ascii=False)
                
            logger.info(f"âœ… çµæœã‚’{filepath}ã«ä¿å­˜ã—ã¾ã—ãŸ")
            
        except Exception as e:
            logger.error(f"âŒ çµæœã®ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def get_chrome_profile_paths(self) -> Dict[str, str]:
        """å„OSã®Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è¿”ã™"""
        system = platform.system()
        
        if system == "Darwin":  # macOS
            return {
                "chrome": "~/Library/Application Support/Google/Chrome",
                "edge": "~/Library/Application Support/Microsoft Edge"
            }
        elif system == "Windows":
            return {
                "chrome": "%LOCALAPPDATA%\\Google\\Chrome\\User Data",
                "edge": "%LOCALAPPDATA%\\Microsoft\\Edge\\User Data"
            }
        else:  # Linux
            return {
                "chrome": "~/.config/google-chrome",
                "chromium": "~/.config/chromium"
            }


# åŒæœŸçš„ãªãƒ©ãƒƒãƒ‘ãƒ¼é–¢æ•°ï¼ˆGUIç”¨ï¼‰
def fetch_models_sync(
    method: Literal["browser", "api", "manual", "cached"] = "browser",
    **kwargs
) -> Dict[str, Dict]:
    """åŒæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
    fetcher = UnifiedModelFetcher()
    return asyncio.run(fetcher.fetch_models(method, **kwargs))


# æ—¢å­˜ã®é–¢æ•°ã¨ã®äº’æ›æ€§ã®ãŸã‚
def fetch_models_browser_session() -> Dict[str, Dict]:
    """ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã§å–å¾—ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ã¨ã®äº’æ›æ€§ï¼‰"""
    return fetch_models_sync("browser")


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    import sys
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸš€ çµ±åˆãƒ¢ãƒ‡ãƒ«å–å¾—ãƒ„ãƒ¼ãƒ«")
    print("\nå–å¾—æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("1. ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆChromeä½¿ç”¨ï¼‰")
    print("2. APIï¼ˆOpenAI APIã‚­ãƒ¼ãŒå¿…è¦ï¼‰")
    print("3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰å–å¾—")
    
    choice = input("\né¸æŠ (1-3): ").strip()
    
    if choice == "1":
        print("\nğŸ“Œ æ³¨æ„: Chromeã«ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
        results = fetch_models_sync("browser")
    elif choice == "2":
        api_key = input("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›: ").strip()
        results = fetch_models_sync("api", api_keys={"chatgpt": api_key})
    elif choice == "3":
        results = fetch_models_sync("cached")
    else:
        print("ç„¡åŠ¹ãªé¸æŠã§ã™")
        sys.exit(1)
    
    print("\nğŸ“Š å–å¾—çµæœ:")
    for service, data in results.items():
        if "error" in data:
            print(f"âŒ {service}: ã‚¨ãƒ©ãƒ¼ - {data['error']}")
        else:
            print(f"âœ… {service}: {data['models']} (method: {data.get('method', 'unknown')})")