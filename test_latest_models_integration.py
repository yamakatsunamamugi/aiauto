#!/usr/bin/env python3
"""
æœ€æ–°ãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ
æ›´æ–°ã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«æƒ…å ±ãŒã‚·ã‚¹ãƒ†ãƒ ã«æ­£ã—ãçµ±åˆã•ã‚Œã¦ã„ã‚‹ã‹ãƒ†ã‚¹ãƒˆ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import json
from src.gui.main_window import MainWindow

def test_latest_models_integration():
    """æœ€æ–°ãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    print("=" * 80)
    print("ğŸ§ª æœ€æ–°AIãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 80)
    
    # MainWindowã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ï¼ˆGUIèµ·å‹•ãªã—ï¼‰
    try:
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
        app = MainWindow()
        
        print("ğŸ“Š çµ±åˆã•ã‚ŒãŸAIãƒ¢ãƒ‡ãƒ«æƒ…å ±:")
        print("-" * 50)
        
        ai_services = ['chatgpt', 'claude', 'gemini', 'genspark', 'google_ai_studio']
        
        for service in ai_services:
            models = app._get_default_models(service)
            features = app._get_default_features(service)
            
            print(f"ğŸ¤– {service.upper()}:")
            print(f"   ğŸ“‹ ãƒ¢ãƒ‡ãƒ«æ•°: {len(models)}")
            print(f"   ğŸ† æœ€æ–°ãƒ¢ãƒ‡ãƒ«: {models[0] if models else 'ãªã—'}")
            print(f"   âš™ï¸  æ©Ÿèƒ½æ•°: {len(features)}")
            print(f"   ğŸ¯ ä¸»è¦æ©Ÿèƒ½: {', '.join(features[:3])}")
            
            # æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã®æ¤œè¨¼
            if service == 'chatgpt' and 'o1-preview' in models:
                print("   âœ… o1-previewãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ˆæœ€æ–°æ¨è«–ãƒ¢ãƒ‡ãƒ«ï¼‰")
            elif service == 'claude' and 'Claude 3.5 Sonnet' in models:
                print("   âœ… Claude 3.5 SonnetãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼‰")
            elif service == 'gemini' and 'Gemini 2.0 Flash' in models:
                print("   âœ… Gemini 2.0 FlashãŒå«ã¾ã‚Œã¦ã„ã¾ã™ï¼ˆæœ€æ–°ãƒ¢ãƒ‡ãƒ«ï¼‰")
            
            # Deep Thinkæ©Ÿèƒ½ã®ç¢ºèª
            if 'Deep Think' in features or 'Deep Research' in features:
                print("   ğŸ§  Deep Think/Researchæ©Ÿèƒ½å¯¾å¿œ")
            
            print()
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
        print("ğŸ“„ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª:")
        print("-" * 50)
        
        try:
            with open('config/ai_models_latest.json', 'r', encoding='utf-8') as f:
                config_data = json.load(f)
            
            print(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
            print(f"ğŸ“… æœ€çµ‚æ›´æ–°: {config_data.get('last_updated', 'N/A')}")
            print(f"ğŸ”„ å–å¾—æ–¹æ³•: {config_data.get('fetch_method', 'N/A')}")
            
            config_services = list(config_data.get('ai_services', {}).keys())
            print(f"ğŸ¤– å¯¾å¿œã‚µãƒ¼ãƒ“ã‚¹: {len(config_services)}å€‹")
            
            for service in config_services:
                service_data = config_data['ai_services'][service]
                model_count = len(service_data.get('models', []))
                feature_count = len(service_data.get('features', []))
                print(f"   {service}: {model_count}ãƒ¢ãƒ‡ãƒ«, {feature_count}æ©Ÿèƒ½")
            
        except Exception as e:
            print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print()
        print("=" * 80)
        print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 80)
        
        # å„ã‚µãƒ¼ãƒ“ã‚¹ã®æœ€æ–°æ€§ãƒã‚§ãƒƒã‚¯
        latest_features = [
            ('ChatGPT', 'o1-preview' in app._get_default_models('chatgpt')),
            ('Claude', 'Claude 3.5 Sonnet' in app._get_default_models('claude')),
            ('Gemini', 'Gemini 2.0 Flash' in app._get_default_models('gemini')),
            ('Deep Thinkå¯¾å¿œ', any('Deep' in feature for features in [app._get_default_features(s) for s in ai_services] for feature in features))
        ]
        
        passed_tests = sum(1 for _, passed in latest_features if passed)
        total_tests = len(latest_features)
        
        for feature_name, passed in latest_features:
            status = "âœ… PASS" if passed else "âŒ FAIL"
            print(f"{status} {feature_name}")
        
        success_rate = (passed_tests / total_tests) * 100
        print(f"\nğŸ“ˆ ç·åˆæˆåŠŸç‡: {passed_tests}/{total_tests} ({success_rate:.1f}%)")
        
        if success_rate >= 75:
            print("ğŸ‰ æœ€æ–°AIãƒ¢ãƒ‡ãƒ«çµ±åˆæˆåŠŸï¼")
            print("ğŸš€ æœ€æ–°ã®o1-previewã€Claude 3.5 Sonnetã€Gemini 2.0 Flashå¯¾å¿œ")
            print("ğŸ’¡ Deep Thinkæ©Ÿèƒ½ã‚‚åˆ©ç”¨å¯èƒ½")
        else:
            print("âš ï¸ ä¸€éƒ¨ã®ãƒ¢ãƒ‡ãƒ«çµ±åˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
        
        return success_rate >= 75
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_latest_models_integration()
    
    if success:
        print("\nâœ… æœ€æ–°ãƒ¢ãƒ‡ãƒ«çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
        print("ğŸ¯ æ¬¡: python3 gui_app.py ã§æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨å¯èƒ½")
    else:
        print("\nâŒ ãƒ¢ãƒ‡ãƒ«çµ±åˆã«å•é¡ŒãŒã‚ã‚Šã¾ã™")