#!/usr/bin/env python3
"""
çµ±åˆãƒ¢ãƒ‡ãƒ«å–å¾—æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import asyncio
import logging
from src.gui.unified_model_fetcher import UnifiedModelFetcher, fetch_models_sync

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_cached_models():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—"""
    print("\n=== ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾— ===")
    results = fetch_models_sync("cached")
    
    for service, info in results.items():
        if "error" in info:
            print(f"âŒ {service}: {info['error']}")
        else:
            models = info.get("models", [])
            method = info.get("method", "unknown")
            print(f"âœ… {service} ({method}): {models}")

def test_api_models():
    """APIçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾—ï¼ˆAPIã‚­ãƒ¼ãŒå¿…è¦ï¼‰"""
    print("\n=== APIçµŒç”±ã§ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’å–å¾— ===")
    print("æ³¨æ„: OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
    
    # ãƒ‡ãƒ¢ç”¨ï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ã™ã¹ãï¼‰
    api_keys = {
        "chatgpt": "sk-..."  # å®Ÿéš›ã®APIã‚­ãƒ¼ã‚’è¨­å®š
    }
    
    if api_keys["chatgpt"] == "sk-...":
        print("âš ï¸ APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return
    
    results = fetch_models_sync("api", api_keys=api_keys)
    
    for service, info in results.items():
        if "error" in info:
            print(f"âŒ {service}: {info['error']}")
        else:
            models = info.get("models", [])
            print(f"âœ… {service}: {models}")

def test_manual_models():
    """æ‰‹å‹•å…¥åŠ›ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
    print("\n=== æ‰‹å‹•å…¥åŠ›ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ ===")
    
    manual_models = {
        "chatgpt": ["gpt-4o", "gpt-4o-mini", "gpt-4-turbo-2024-11-20"],
        "claude": ["claude-3.5-sonnet-20241022", "claude-3-opus"],
        "gemini": ["gemini-1.5-pro-latest", "gemini-1.5-flash"]
    }
    
    results = fetch_models_sync("manual", manual_models=manual_models)
    
    for service, info in results.items():
        models = info.get("models", [])
        print(f"âœ… {service}: {models}")

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("ğŸš€ çµ±åˆãƒ¢ãƒ‡ãƒ«å–å¾—æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # 1. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ã®å–å¾—ã‚’ãƒ†ã‚¹ãƒˆ
    test_cached_models()
    
    # 2. æ‰‹å‹•å…¥åŠ›ã®ãƒ†ã‚¹ãƒˆ
    test_manual_models()
    
    # 3. APIçµŒç”±ã®ãƒ†ã‚¹ãƒˆï¼ˆAPIã‚­ãƒ¼ãŒã‚ã‚‹å ´åˆï¼‰
    test_api_models()
    
    # 4. ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã®èª¬æ˜
    print("\n=== ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã«ã¤ã„ã¦ ===")
    print("ãƒ–ãƒ©ã‚¦ã‚¶ã‚»ãƒƒã‚·ãƒ§ãƒ³æ–¹å¼ã¯å®Ÿéš›ã®Chromeã‚’é–‹ããŸã‚ã€")
    print("GUIã‚¢ãƒ—ãƒªã‹ã‚‰å®Ÿè¡Œã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
    print("å®Ÿè¡Œä¾‹: results = fetch_models_sync('browser')")
    
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()