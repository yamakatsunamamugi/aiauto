"""
Ollamaçµ±åˆãƒ†ã‚¹ãƒˆ
æ‹…å½“è€…ï¼šAI-A
ä½œæˆæ—¥ï¼š2024å¹´6æœˆ12æ—¥
"""

import pytest
import sys
import os
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

try:
    from src.automation.ollama_handler import OllamaAIHandler
    from src.automation.ollama_config import OllamaConfig
    OLLAMA_HANDLER_AVAILABLE = True
except ImportError as e:
    print(f"ImportError: {e}")
    OLLAMA_HANDLER_AVAILABLE = False


class TestOllamaIntegration:
    """Ollamaçµ±åˆãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def setup_method(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        if not OLLAMA_HANDLER_AVAILABLE:
            pytest.skip("Ollama handler not available")
        
        try:
            self.handler = OllamaAIHandler()
        except Exception as e:
            pytest.skip(f"Ollama service not available: {e}")

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_handler_initialization(self):
        """ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        assert self.handler is not None
        assert hasattr(self.handler, 'client')
        assert hasattr(self.handler, 'available_models')
        assert hasattr(self.handler, 'stats')

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_basic_text_processing(self):
        """åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        test_text = "ã“ã‚“ã«ã¡ã¯ã€ãƒ†ã‚¹ãƒˆã§ã™ã€‚ç°¡æ½”ã«æŒ¨æ‹¶ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"
        result = self.handler.process_text(test_text)

        assert "success" in result
        assert "processing_time" in result
        assert "timestamp" in result
        assert "model_used" in result

        if result["success"]:
            assert "result" in result
            assert isinstance(result["result"], str)
            assert len(result["result"]) > 0
            print(f"âœ… å‡¦ç†æˆåŠŸ: {result['result'][:100]}...")
        else:
            assert "error" in result
            print(f"âŒ å‡¦ç†å¤±æ•—: {result['error']}")

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_model_validation(self):
        """ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚‹å ´åˆ
        if self.handler.available_models:
            valid_model = self.handler.available_models[0]
            assert self.handler.validate_model(valid_model) == True
        
        # å­˜åœ¨ã—ãªã„ãƒ¢ãƒ‡ãƒ«
        invalid_model = "nonexistent:model"
        assert self.handler.validate_model(invalid_model) == False

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_statistics(self):
        """çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆ"""
        stats = self.handler.get_statistics()

        assert "total_requests" in stats
        assert "successful_requests" in stats
        assert "failed_requests" in stats
        assert "average_response_time" in stats
        
        # çµ±è¨ˆãŒæ•°å€¤ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert isinstance(stats["total_requests"], int)
        assert isinstance(stats["successful_requests"], int)
        assert isinstance(stats["failed_requests"], int)
        assert isinstance(stats["average_response_time"], (int, float))

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_health_check(self):
        """å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        health = self.handler.health_check()
        
        assert "status" in health
        assert health["status"] in ["healthy", "unhealthy", "error"]
        
        if health["status"] == "healthy":
            assert "available_models" in health
            assert "statistics" in health
            assert "test_result" in health

    @pytest.mark.skipif(not OLLAMA_HANDLER_AVAILABLE, reason="Ollama handler not available")
    def test_system_prompt(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ"""
        test_text = "æ•°å­—ã®3ã‚’æ•™ãˆã¦"
        system_prompt = "æ•°å­—ã«ã¤ã„ã¦èã‹ã‚ŒãŸã‚‰ã€ãã®æ•°å­—ã ã‘ã‚’ç­”ãˆã¦ãã ã•ã„ã€‚"
        
        result = self.handler.process_text(test_text, system_prompt=system_prompt)
        
        if result["success"]:
            print(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçµæœ: {result['result']}")
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒåŠ¹ã„ã¦ã„ã‚‹ã‹ã®ç°¡æ˜“ãƒã‚§ãƒƒã‚¯
            assert "3" in result["result"]


class TestOllamaConfig:
    """Ollamaè¨­å®šãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""

    def test_default_config(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ†ã‚¹ãƒˆ"""
        config = OllamaConfig.get_default_config()
        
        assert "models" in config
        assert "default_model" in config
        assert "system_prompts" in config
        assert "options" in config
        
        # å¿…é ˆé …ç›®ã®å­˜åœ¨ç¢ºèª
        assert isinstance(config["models"], list)
        assert len(config["models"]) > 0
        assert isinstance(config["system_prompts"], dict)
        assert isinstance(config["options"], dict)

    def test_model_recommendations(self):
        """ãƒ¢ãƒ‡ãƒ«æ¨å¥¨è¨­å®šãƒ†ã‚¹ãƒˆ"""
        recommendations = OllamaConfig.get_model_recommendations()
        
        expected_keys = ["speed_priority", "quality_priority", "reasoning_priority", "creative_priority"]
        for key in expected_keys:
            assert key in recommendations
            assert "model" in recommendations[key]
            assert "description" in recommendations[key]
            assert "options" in recommendations[key]

    def test_config_validation(self):
        """è¨­å®šæ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""
        # æ­£å¸¸ãªè¨­å®š
        valid_config = {
            "default_model": "llama3.1:8b",
            "options": {
                "temperature": 0.7,
                "num_predict": 2000
            }
        }
        result = OllamaConfig.validate_config(valid_config)
        assert len(result["errors"]) == 0

        # ç•°å¸¸ãªè¨­å®š
        invalid_config = {
            "options": {
                "temperature": 5.0,  # ç¯„å›²å¤–
                "num_predict": -1    # ç¯„å›²å¤–
            }
        }
        result = OllamaConfig.validate_config(invalid_config)
        assert len(result["errors"]) > 0  # default_model ãŒä¸è¶³


def run_integration_tests():
    """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–¢æ•°"""
    print("ğŸ§ª Ollamaçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO)
    
    # è¨­å®šãƒ†ã‚¹ãƒˆ
    print("\nğŸ“‹ è¨­å®šãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    config_test = TestOllamaConfig()
    config_test.test_default_config()
    config_test.test_model_recommendations()
    config_test.test_config_validation()
    print("âœ… è¨­å®šãƒ†ã‚¹ãƒˆå®Œäº†")
    
    # Ollamaãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆ
    print("\nğŸ¤– Ollamaãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
    try:
        handler_test = TestOllamaIntegration()
        handler_test.setup_method()
        
        handler_test.test_handler_initialization()
        print("âœ… ãƒãƒ³ãƒ‰ãƒ©ãƒ¼åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        handler_test.test_statistics()
        print("âœ… çµ±è¨ˆæƒ…å ±ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        handler_test.test_model_validation()
        print("âœ… ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        handler_test.test_health_check()
        print("âœ… å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        # å®Ÿéš›ã®AIå‡¦ç†ãƒ†ã‚¹ãƒˆï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ï¼‰
        print("\nğŸ”„ å®Ÿéš›ã®AIå‡¦ç†ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        handler_test.test_basic_text_processing()
        print("âœ… åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†ãƒ†ã‚¹ãƒˆå®Œäº†")
        
        handler_test.test_system_prompt()
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"âš ï¸ Ollamaãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—: {e}")
    
    print("\nğŸ‰ å…¨ã¦ã®Ollamaçµ±åˆãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")


if __name__ == "__main__":
    run_integration_tests()